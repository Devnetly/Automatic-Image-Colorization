{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-31T16:35:35.690398Z","iopub.status.busy":"2024-03-31T16:35:35.689787Z","iopub.status.idle":"2024-03-31T16:35:35.696336Z","shell.execute_reply":"2024-03-31T16:35:35.695150Z","shell.execute_reply.started":"2024-03-31T16:35:35.690366Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import glob\n","import time\n","import numpy as np\n","from PIL import Image\n","import pandas as pd\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","from skimage.color import rgb2lab, lab2rgb\n","\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","\n","import sys\n","sys.path.append('../src')\n","from dataset import ColorizationDataset\n","from model import MainModel\n","from loss import AverageMeter\n","\n","from dotenv import load_dotenv\n","load_dotenv()\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:35:41.232093Z","iopub.status.busy":"2024-03-31T16:35:41.231398Z","iopub.status.idle":"2024-03-31T16:35:41.257014Z","shell.execute_reply":"2024-03-31T16:35:41.255989Z","shell.execute_reply.started":"2024-03-31T16:35:41.232063Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 16\n","LEARNING_RATE = 0.001\n","EPOCHS = 400000\n","SIZE = 256\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","DATA_DIR = os.path.join(os.getenv('DATASET_PATH'), \"coco-2017-dataset\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'D:\\\\\\\\AIDS\\\\\\\\S2\\\\\\\\Project\\\\coco-2017-dataset'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["DATA_DIR"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:35:44.760165Z","iopub.status.busy":"2024-03-31T16:35:44.759796Z","iopub.status.idle":"2024-03-31T16:35:46.131859Z","shell.execute_reply":"2024-03-31T16:35:46.131018Z","shell.execute_reply.started":"2024-03-31T16:35:44.760136Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["16000 3305\n"]}],"source":["paths = glob.glob(DATA_DIR+\"/coco2017/train2017/*.jpg\")\n","train_paths = paths[:16000] \n","val_paths = paths[16000:]\n","print(len(train_paths), len(val_paths))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:35:46.473055Z","iopub.status.busy":"2024-03-31T16:35:46.472400Z","iopub.status.idle":"2024-03-31T16:35:47.641025Z","shell.execute_reply":"2024-03-31T16:35:47.639899Z","shell.execute_reply.started":"2024-03-31T16:35:46.473023Z"},"trusted":true},"outputs":[],"source":["def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, size = SIZE, **kwargs): # A handy function to make our dataloaders\n","    dataset = ColorizationDataset(size= size, **kwargs)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n","                            pin_memory=pin_memory)\n","    return dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256])\n","1000 207\n"]}],"source":["train_dl = make_dataloaders(paths=train_paths, split='train')\n","val_dl = make_dataloaders(paths=val_paths, split='val')\n","\n","data = next(iter(train_dl))\n","Ls, abs_ = data['L'], data['ab']\n","print(Ls.shape, abs_.shape)\n","print(len(train_dl), len(val_dl))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:35:52.401848Z","iopub.status.busy":"2024-03-31T16:35:52.401060Z","iopub.status.idle":"2024-03-31T16:35:53.070218Z","shell.execute_reply":"2024-03-31T16:35:53.069310Z","shell.execute_reply.started":"2024-03-31T16:35:52.401809Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model initialized with norm initialization\n","model initialized with norm initialization\n"]}],"source":["model = MainModel()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:35:53.938349Z","iopub.status.busy":"2024-03-31T16:35:53.937540Z","iopub.status.idle":"2024-03-31T16:35:53.953981Z","shell.execute_reply":"2024-03-31T16:35:53.953021Z","shell.execute_reply.started":"2024-03-31T16:35:53.938316Z"},"trusted":true},"outputs":[],"source":["def create_loss_meters():\n","    loss_D_fake = AverageMeter()\n","    loss_D_real = AverageMeter()\n","    loss_D = AverageMeter()\n","    loss_G_GAN = AverageMeter()\n","    loss_G_L1 = AverageMeter()\n","    loss_G = AverageMeter()\n","    \n","    return {'loss_D_fake': loss_D_fake,\n","            'loss_D_real': loss_D_real,\n","            'loss_D': loss_D,\n","            'loss_G_GAN': loss_G_GAN,\n","            'loss_G_L1': loss_G_L1,\n","            'loss_G': loss_G}\n","\n","def update_losses(model, loss_meter_dict, count):\n","    for loss_name, loss_meter in loss_meter_dict.items():\n","        loss = getattr(model, loss_name)\n","        loss_meter.update(loss.item(), count=count)\n","\n","def lab_to_rgb(L, ab):\n","    \"\"\"\n","    Takes a batch of images\n","    \"\"\"\n","    \n","    L = (L + 1.) * 50.\n","    ab = ab * 110.\n","    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n","    rgb_imgs = []\n","    for img in Lab:\n","        img_rgb = lab2rgb(img)\n","        rgb_imgs.append(img_rgb)\n","    return np.stack(rgb_imgs, axis=0)\n","    \n","def visualize(model, data, save=True):\n","    model.net_G.eval()\n","    with torch.no_grad():\n","        model.setup_input(data)\n","        model.forward()\n","    model.net_G.train()\n","    fake_color = model.fake_color.detach()\n","    real_color = model.ab\n","    L = model.L\n","    fake_imgs = lab_to_rgb(L, fake_color)\n","    real_imgs = lab_to_rgb(L, real_color)\n","    fig = plt.figure(figsize=(15, 8))\n","    for i in range(5):\n","        ax = plt.subplot(3, 5, i + 1)\n","        ax.imshow(L[i][0].cpu(), cmap='gray')\n","        ax.axis(\"off\")\n","        ax = plt.subplot(3, 5, i + 1 + 5)\n","        ax.imshow(fake_imgs[i])\n","        ax.axis(\"off\")\n","        ax = plt.subplot(3, 5, i + 1 + 10)\n","        ax.imshow(real_imgs[i])\n","        ax.axis(\"off\")\n","    plt.show()\n","    if save:\n","        fig.savefig(f\"colorization_{time.time()}.png\")\n","        \n","def log_results(loss_meter_dict):\n","    results = {}\n","    for loss_name, loss_meter in loss_meter_dict.items():\n","        results[loss_name] = loss_meter.avg\n","        print(f\"{loss_name}: {loss_meter.avg:.5f}\")\n","    return results"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def validate(model, val_dl):\n","    model.net_G.eval()\n","    l1_loss = 0.0\n","    gan_loss = 0.0\n","    with torch.no_grad():\n","        for data in val_dl:\n","            model.setup_input(data)\n","            model.forward()\n","            fake_color = model.fake_color\n","            real_color = model.ab\n","            val_loss += model.L1criterion(fake_color, real_color).item() * data['L'].size(0)\n","            gan_loss += model.GANcriterion(model.net_D(fake_color), True).item() * data['L'].size(0)\n","    val_loss /= len(val_dl.dataset)\n","    model.net_G.train()\n","    return val_loss"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T17:34:08.955890Z","iopub.status.busy":"2024-03-31T17:34:08.955060Z"},"trusted":true},"outputs":[],"source":["def train_model(model, train_dl, val_dl, epochs, display_every=800):\n","    df = pd.DataFrame()  # Initialize an empty DataFrame\n","    loss_history = []  # List to store loss history\n","    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intervals\n","    for e in range(epochs):\n","        loss_meter_dict = create_loss_meters() # function returning a dictionary of objects to log the losses of the complete network\n","        i = 0\n","        for data in tqdm(train_dl):\n","            model.setup_input(data) \n","            model.optimize()\n","            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n","            i += 1\n","            if i % display_every == 0:\n","                print(f\"\\nEpoch {e+1}/{epochs}\")\n","                print(f\"Iteration {i}/{len(train_dl)}\")\n","                row = log_results(loss_meter_dict) # function to print out the losses\n","                row[\"epoch\"] = e\n","                df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)  # Append the row to the DataFrame\n","        val_loss = validate(model, val_dl)\n","        print(f\"Validation Loss: {val_loss:.5f}\")\n","        df.to_csv(f\"val_losses_{e} \"\".csv\", index=False)\n","    return df"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6152985bbf7342cd86ce8f5c0cc838f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1/1\n","Iteration 800/1000\n","loss_D_fake: 0.49253\n","loss_D_real: 0.51703\n","loss_D: 0.50478\n","loss_G_GAN: 1.46858\n","loss_G_L1: 10.31413\n","loss_G: 11.78271\n","Validation Loss: 0.11404\n"]}],"source":["df = train_model(model, train_dl, val_dl, 1)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'normal_gan1ep.pt')\n","df.to_csv('normal_gan1ep.csv', index=False)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:50:24.899186Z","iopub.status.busy":"2024-03-31T16:50:24.898813Z","iopub.status.idle":"2024-03-31T16:50:24.905042Z","shell.execute_reply":"2024-03-31T16:50:24.904031Z","shell.execute_reply.started":"2024-03-31T16:50:24.899159Z"},"trusted":true},"outputs":[],"source":["from fastai.vision.learner import create_body\n","from torchvision.models.resnet import resnet18\n","from fastai.vision.models.unet import DynamicUnet\n","\n","\n","def build_res_unet(n_input=1, n_output=2, size=256):\n","    body = create_body(resnet18(), pretrained=True, n_in=n_input, cut=-2)\n","    net_G = DynamicUnet(body, n_output, (size, size)).to(DEVICE)\n","    return net_G"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T16:50:55.176463Z","iopub.status.busy":"2024-03-31T16:50:55.176070Z","iopub.status.idle":"2024-03-31T17:08:34.124089Z","shell.execute_reply":"2024-03-31T17:08:34.122595Z","shell.execute_reply.started":"2024-03-31T16:50:55.176427Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c4de9c3a3254f609036ccd751c54a9e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","L1 Loss: 0.08652\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4db91ecdd7e40fcbf60c98a8db7190b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2/20\n","L1 Loss: 0.08287\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"233f0667905c41dc95403afd90c7e281","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3/20\n","L1 Loss: 0.08222\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41067cc12b5c42e18817894ca5965302","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4/20\n","L1 Loss: 0.08141\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08dcb949321a4410b3e9526102a48741","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5/20\n","L1 Loss: 0.08081\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd335068656647adbd753f734f8c77e7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6/20\n","L1 Loss: 0.08026\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"408f331e630441d3a5b2c2aca0eeac2f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m opt \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(net_G\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     19\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()        \n\u001b[0;32m---> 20\u001b[0m \u001b[43mpretrain_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_G\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(net_G\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mres18-unet.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[28], line 12\u001b[0m, in \u001b[0;36mpretrain_generator\u001b[0;34m(net_G, train_dl, opt, criterion, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     10\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 12\u001b[0m     loss_meter\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, L\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL1 Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_meter\u001b[38;5;241m.\u001b[39mavg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:1386\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1386\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n","    loss_history = []  # List to store loss history\n","    for e in range(epochs):\n","        loss_meter = AverageMeter()\n","        for data in tqdm(train_dl):\n","            L, ab = data['L'].to(DEVICE), data['ab'].to(DEVICE)\n","            preds = net_G(L)\n","            loss = criterion(preds, ab)\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            \n","            loss_meter.update(loss.item(), L.size(0))\n","        \n","        loss_history.append(loss_meter.avg)  # Append loss to history\n","        \n","        print(f\"Epoch {e + 1}/{epochs}\")\n","        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n","\n","    np.save('res18-unet.npy', loss_history)  # Save loss history as .npy file\n","\n","net_G = build_res_unet(n_input=1, n_output=2, size=256)\n","opt = optim.Adam(net_G.parameters(), lr=1e-4)\n","criterion = nn.L1Loss()        \n","pretrain_generator(net_G, train_dl, opt, criterion, 20)\n","torch.save(net_G.state_dict(), \"res18-unet.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net_G = build_res_unet(n_input=1, n_output=2, size=256)\n","net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n","model = MainModel(net_G=net_G)\n","train_model(model, train_dl, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), 'resnet_gan.pt')\n","np.save('resnet_gan.npy', loss_history)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":857191,"sourceId":1462296,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
